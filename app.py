import streamlit as st
import pandas as pd
import io
from functools import reduce


# --- é€šç”¨è¼”åŠ©å‡½æ•¸ ---
def to_excel(df):
    """å°‡ DataFrame è½‰æ›ç‚ºå¯ä¾›ä¸‹è¼‰çš„ Excel Bytes ç‰©ä»¶"""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='åˆä½µçµæœ')
    processed_data = output.getvalue()
    return processed_data


def read_and_clean_sheet(file_obj, sheet_name, header_index=0):
    """è®€å–æŒ‡å®šçš„ Excel å·¥ä½œè¡¨ä¸¦é€²è¡ŒåŸºæœ¬æ¸…ç†"""
    file_obj.seek(0)
    df = pd.read_excel(file_obj, sheet_name=sheet_name, header=header_index)
    df.columns = [str(col) for col in df.columns]
    return df


def highlight_duplicated_keys(row, duplicated_keys_set, key_columns):
    """å¦‚æœè¡Œçš„ç´¢å¼•éµåœ¨é‡è¤‡é›†åˆä¸­ï¼Œå‰‡æ¨™è¨»èƒŒæ™¯è‰²"""
    color = 'background-color: #fff9c4'
    default_color = ''
    if tuple(row[key_columns]) in duplicated_keys_set:
        return [color] * len(row)
    return [default_color] * len(row)


# --- Streamlit æ‡‰ç”¨ç¨‹å¼ä»‹é¢ ---
st.set_page_config(page_title="Excel å…¨èƒ½åˆä½µå·¥å…·", page_icon="ğŸ§©", layout="wide")

st.title("ğŸ§© Excel å…¨èƒ½åˆä½µå·¥å…·")

# --- æ¨¡å¼é¸æ“‡ ---
app_mode = st.radio(
    "è«‹é¸æ“‡æ‚¨è¦ä½¿ç”¨çš„å·¥å…·æ¨¡å¼ï¼š",
    ('é›™æª”æŸ¥æ‰¾åˆä½µ (VLOOKUP)', 'å¤šæª”åˆä½µ (ç¸±å‘/æ©«å‘)'),
    horizontal=True,
)
st.divider()

# åˆå§‹åŒ– session_state
if 'final_df' not in st.session_state:
    st.session_state.final_df = None
if 'duplication_warning_keys' not in st.session_state:
    st.session_state.duplication_warning_keys = []

# ==============================================================================
# æ¨¡å¼ä¸€ï¼šé›™æª”æŸ¥æ‰¾åˆä½µ (VLOOKUP)
# ==============================================================================
if app_mode == 'é›™æª”æŸ¥æ‰¾åˆä½µ (VLOOKUP)':
    st.header("æ¨¡å¼ï¼šé›™æª”æŸ¥æ‰¾åˆä½µ (VLOOKUP)")
    st.markdown("æ­¤æ¨¡å¼æœƒä»¥**å·¦è¡¨**ç‚ºåŸºç¤ï¼Œå¾**å³è¡¨**ä¸­æŸ¥æ‰¾ç¬¦åˆæ¢ä»¶çš„è³‡æ–™ï¼Œä¸¦å°‡æŒ‡å®šæ¬„ä½æ–°å¢è‡³å·¦è¡¨ã€‚")

    st.subheader("æ­¥é©Ÿä¸€ï¼šä¸Šå‚³æª”æ¡ˆä¸¦é¸æ“‡å·¥ä½œè¡¨")
    col1, col2 = st.columns(2)
    df_left, df_right = None, None

    with col1:
        st.markdown("##### ğŸ‘ˆ ä¸»è¦æª”æ¡ˆ (å·¦è¡¨)")
        uploaded_file_left = st.file_uploader("é€™æ˜¯æ‚¨è¦ä¿ç•™æ‰€æœ‰è³‡æ–™çš„æª”æ¡ˆ", type=["xlsx", "xls"], key="uploader_left")
        if uploaded_file_left:
            try:
                file_buffer_left = io.BytesIO(uploaded_file_left.getvalue())
                sheet_names_left = pd.ExcelFile(file_buffer_left).sheet_names
                left_sheet_name = st.selectbox("é¸æ“‡ä¸»è¦å·¥ä½œè¡¨", sheet_names_left, key="sheet_left")
                header_left = st.number_input("å·¦è¡¨æ¨™é ­åœ¨ç¬¬å¹¾åˆ—?", min_value=1, value=1, key="header_left")
                if left_sheet_name:
                    df_left = read_and_clean_sheet(file_buffer_left, left_sheet_name, header_left - 1)
                    st.write("å·¦è¡¨é è¦½ï¼š")
                    st.dataframe(df_left.head(), height=200)
            except Exception as e:
                st.error(f"è®€å–å·¦è¡¨å¤±æ•—: {e}")

    with col2:
        st.markdown("##### ğŸ‘‰ æŸ¥æ‰¾è³‡æ–™æª”æ¡ˆ (å³è¡¨)")
        uploaded_file_right = st.file_uploader("é€™æ˜¯æ‚¨è¦å¾ä¸­æå–è³‡æ–™çš„æª”æ¡ˆ", type=["xlsx", "xls"], key="uploader_right")
        if uploaded_file_right:
            try:
                file_buffer_right = io.BytesIO(uploaded_file_right.getvalue())
                sheet_names_right = pd.ExcelFile(file_buffer_right).sheet_names
                right_sheet_name = st.selectbox("é¸æ“‡æŸ¥æ‰¾è³‡æ–™çš„å·¥ä½œè¡¨", sheet_names_right, key="sheet_right")
                header_right = st.number_input("å³è¡¨æ¨™é ­åœ¨ç¬¬å¹¾åˆ—?", min_value=1, value=1, key="header_right")
                if right_sheet_name:
                    df_right = read_and_clean_sheet(file_buffer_right, right_sheet_name, header_right - 1)
                    st.write("å³è¡¨é è¦½ï¼š")
                    st.dataframe(df_right.head(), height=200)
            except Exception as e:
                st.error(f"è®€å–å³è¡¨å¤±æ•—: {e}")

    if df_left is not None and df_right is not None:
        st.divider()
        st.subheader("æ­¥é©ŸäºŒï¼šè¨­å®šåˆä½µæ¢ä»¶ä¸¦åŸ·è¡Œ")
        common_columns = list(set(df_left.columns) & set(df_right.columns))

        if not common_columns:
            st.error("éŒ¯èª¤ï¼šå…©å€‹å·¥ä½œè¡¨ä¹‹é–“æ²’æœ‰ä»»ä½•å…±åŒçš„æ¬„ä½åç¨±ï¼Œç„¡æ³•é€²è¡Œåˆä½µã€‚")
        else:
            with st.form("vlookup_form"):
                merge_keys = st.multiselect("é¸æ“‡ç”¨ä¾†å°æ‡‰çš„æ¬„ä½ (å…±åŒç´¢å¼•éµ)", common_columns, default=common_columns[:1])
                available_cols_from_right = [col for col in df_right.columns if col not in merge_keys]
                cols_to_merge = st.multiselect("é¸æ“‡è¦å¾å³è¡¨åŠ å…¥åˆ°å·¦è¡¨çš„æ¬„ä½", available_cols_from_right,
                                               default=available_cols_from_right)

                submitted_vlookup = st.form_submit_button("ğŸš€ åŸ·è¡ŒæŸ¥æ‰¾åˆä½µ", type="primary")

            if submitted_vlookup:
                st.session_state.final_df = None
                st.session_state.duplication_warning_keys = []

                if not merge_keys:
                    st.warning("è«‹é¸æ“‡è‡³å°‘ä¸€å€‹ç”¨ä¾†å°æ‡‰çš„å…±åŒç´¢å¼•éµã€‚")
                else:
                    with st.spinner("æ­£åœ¨åˆä½µè³‡æ–™ä¸¦é€²è¡Œåˆ†æ..."):
                        try:
                            duplicated_rows = df_right[df_right.duplicated(subset=merge_keys, keep=False)]
                            if not duplicated_rows.empty:
                                st.session_state.duplication_warning_keys = duplicated_rows[
                                    merge_keys].drop_duplicates().values.tolist()

                            df_right_selected = df_right[merge_keys + cols_to_merge]
                            merged_df = pd.merge(df_left, df_right_selected, on=merge_keys, how='left')

                            duplicated_keys = st.session_state.get('duplication_warning_keys', [])
                            if duplicated_keys:
                                merged_df['å‚™è¨»'] = ''
                                condition = merged_df[merge_keys].apply(tuple, axis=1).isin(
                                    [tuple(x) for x in duplicated_keys])
                                merged_df.loc[condition, 'å‚™è¨»'] = 'ä¸€å°å¤šé—œä¿‚æé†’'

                            st.session_state.final_df = merged_df
                            st.success("ğŸ‰ æŸ¥æ‰¾åˆä½µæˆåŠŸï¼")

                        except Exception as e:
                            st.error(f"åˆä½µå¤±æ•—: {e}")

# ==============================================================================
# æ¨¡å¼äºŒï¼šå¤šæª”åˆä½µ (ç¸±å‘/æ©«å‘)
# ==============================================================================
elif app_mode == 'å¤šæª”åˆä½µ (ç¸±å‘/æ©«å‘)':
    st.header("æ¨¡å¼ï¼šå¤šæª”åˆä½µ (ç¸±å‘/æ©«å‘)")
    st.markdown("æ­¤æ¨¡å¼å¯åˆä½µå¤šå€‹æª”æ¡ˆï¼Œæˆ–å–®ä¸€æª”æ¡ˆå…§çš„å¤šå€‹å·¥ä½œè¡¨ã€‚")

    uploaded_files = st.file_uploader(
        "è«‹ä¸Šå‚³æ‚¨æ‰€æœ‰è¦è™•ç†çš„ Excel æª”æ¡ˆ",
        type=['xlsx', 'xls'],
        accept_multiple_files=True,
        key="multi_file_uploader"
    )

    if uploaded_files:
        with st.form("multi_merge_form"):
            st.subheader("1. åˆä½µæ¨¡å¼è¨­å®š")
            merge_type = st.radio("è«‹é¸æ“‡åˆä½µæ–¹å¼ï¼š", ('ç¸±å‘åˆä½µ (ä¸Šä¸‹å †ç–Š)', 'æ©«å‘åˆä½µ (å·¦å³æ‹¼æ¥)'), horizontal=True)
            header_row_from_user = st.number_input("æ‰€æœ‰æª”æ¡ˆçš„æ¨™é ­ (Header) éƒ½åœ¨ç¬¬å¹¾åˆ—ï¼Ÿ", min_value=1, value=1)

            file_configs = {}
            for uploaded_file in uploaded_files:
                try:
                    file_buffer = io.BytesIO(uploaded_file.getvalue())
                    xls = pd.ExcelFile(file_buffer)
                    sheet_names = xls.sheet_names
                    file_configs[uploaded_file.name] = {"file_object": file_buffer, "sheet_names": sheet_names}
                except Exception as e:
                    st.error(f"è®€å–æª”æ¡ˆ '{uploaded_file.name}' çš„å·¥ä½œè¡¨åˆ—è¡¨å¤±æ•—: {e}")

            join_keys = []
            join_how = "inner"

            st.divider()
            st.subheader("2. æª”æ¡ˆèˆ‡å·¥ä½œè¡¨è¨­å®š")
            all_selected_sheets_info = []
            for filename, config in file_configs.items():
                selected_sheets = st.multiselect(
                    f"æª”æ¡ˆ: `{filename}` - è«‹å‹¾é¸è¦åˆä½µçš„å·¥ä½œè¡¨",
                    options=config["sheet_names"],
                    default=config["sheet_names"][0] if config["sheet_names"] else None,
                    key=f"sheets_{filename}"
                )
                config["selected_sheets"] = selected_sheets
                for sheet in selected_sheets:
                    all_selected_sheets_info.append((config["file_object"], sheet))

            if merge_type == 'æ©«å‘åˆä½µ (å·¦å³æ‹¼æ¥)':
                st.divider()
                st.subheader("3. æ©«å‘åˆä½µå°ˆç”¨è¨­å®š")

                common_columns_for_key = []
                if all_selected_sheets_info:
                    try:
                        dfs_for_cols = [read_and_clean_sheet(f[0], f[1], header_row_from_user - 1) for f in
                                        all_selected_sheets_info]
                        if dfs_for_cols:
                            column_sets = [set(df.columns) for df in dfs_for_cols]
                            common_columns_for_key = list(set.intersection(*column_sets))
                    except Exception as e:
                        st.warning(f"è¨ˆç®—å…±åŒæ¬„ä½æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

                if not common_columns_for_key:
                    st.warning("æ‚¨ç›®å‰é¸æ“‡çš„å·¥ä½œè¡¨ä¹‹é–“æ²’æœ‰å…±åŒæ¬„ä½ï¼Œç„¡æ³•é€²è¡Œæ©«å‘åˆä½µã€‚")
                else:
                    join_keys = st.multiselect("è«‹é¸æ“‡ç”¨ä¾†å°é½Šçš„ã€Œå…±åŒæ¬„ä½ã€(Keys)", common_columns_for_key,
                                               default=common_columns_for_key[:1])

                merge_options_display = {
                    "å…§é€£æ¥ (Inner Join) - åªä¿ç•™æ‰€æœ‰è¡¨ä¸­å…±æœ‰çš„è³‡æ–™": "inner",
                    "å¤–é€£æ¥ (Outer Join) - ä¿ç•™æ‰€æœ‰è¡¨ä¸­å‡ºç¾éçš„è³‡æ–™": "outer",
                    "å·¦é€£æ¥ (Left Join) - ä»¥ç¬¬ä¸€å€‹é¸æ“‡çš„è¡¨ç‚ºåŸºç¤": "left",
                }
                selected_display = st.selectbox(
                    "é¸æ“‡åˆä½µé¡å‹",
                    options=list(merge_options_display.keys()),
                    help="æ±ºå®šå¦‚ä½•è™•ç†åœ¨ä¸åŒè¡¨ä¸­ç„¡æ³•å°æ‡‰çš„è³‡æ–™ã€‚"
                )
                join_how = merge_options_display[selected_display]

            st.divider()
            st.subheader("4. å…¶ä»–è¨­å®š")
            add_source_col = st.checkbox("æ–°å¢ã€Œä¾†æºæª”æ¡ˆ/å·¥ä½œè¡¨ã€æ¬„ä½ (åƒ…åœ¨ç¸±å‘åˆä½µæ™‚æœ‰æ•ˆ)", value=True)
            submitted = st.form_submit_button("ğŸš€ åŸ·è¡Œå¤šæª”åˆä½µ", type="primary")

        if submitted:
            st.session_state.final_df = None

            all_dfs_to_merge = []
            with st.spinner('æ­£åœ¨è®€å–æ‰€æœ‰é¸å®šçš„å·¥ä½œè¡¨...'):
                for filename, config in file_configs.items():
                    if "selected_sheets" in config:
                        for sheet_name in config["selected_sheets"]:
                            df = read_and_clean_sheet(config["file_object"], sheet_name, header_row_from_user - 1)
                            if add_source_col and merge_type == 'ç¸±å‘åˆä½µ (ä¸Šä¸‹å †ç–Š)':
                                df['ä¾†æºæª”æ¡ˆ'] = filename
                                df['ä¾†æºå·¥ä½œè¡¨'] = sheet_name
                            all_dfs_to_merge.append(df)

            if not all_dfs_to_merge:
                st.warning("æœªæˆåŠŸè®€å–ä»»ä½•å·¥ä½œè¡¨ã€‚")
            else:
                merged_df = None
                with st.spinner('æ­£åœ¨åŸ·è¡Œåˆä½µ...'):
                    try:
                        if merge_type == 'ç¸±å‘åˆä½µ (ä¸Šä¸‹å †ç–Š)':
                            merged_df = pd.concat(all_dfs_to_merge, ignore_index=True)
                        else:  # æ©«å‘åˆä½µ
                            if not join_keys:
                                st.error("æ©«å‘åˆä½µéŒ¯èª¤ï¼šå¿…é ˆæä¾›ã€Œå…±åŒæ¬„ä½ã€ã€‚")
                            elif len(all_dfs_to_merge) < 2:
                                st.warning("æ©«å‘åˆä½µè‡³å°‘éœ€è¦å…©å€‹å·¥ä½œè¡¨ã€‚")
                            else:
                                renamed_dfs = []
                                for i, df in enumerate(all_dfs_to_merge):
                                    renamed_columns = {col: f"{col}_df{i + 1}" for col in df.columns if
                                                       col not in join_keys}
                                    df = df.rename(columns=renamed_columns)
                                    renamed_dfs.append(df)

                                merged_df = reduce(
                                    lambda left, right: pd.merge(left, right, on=join_keys, how=join_how), renamed_dfs)

                        if merged_df is not None:
                            st.session_state.final_df = merged_df
                            st.success("ğŸ‰ åˆä½µæˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"åˆä½µå¤±æ•—: {e}")

# --- é€šç”¨çµæœé¡¯ç¤ºå€ ---
if 'final_df' in st.session_state and st.session_state.final_df is not None:
    st.divider()
    st.header("âœ… åˆä½µçµæœé è¦½èˆ‡ä¸‹è¼‰")
    final_df = st.session_state.final_df
    st.info(f"åˆä½µçµæœï¼šå…± {final_df.shape[0]} ç­†è³‡æ–™ï¼Œ{final_df.shape[1]} å€‹æ¬„ä½ã€‚")
    st.dataframe(final_df, use_container_width=True)

    excel_data = to_excel(final_df)
    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰åˆä½µçµæœ",
        data=excel_data,
        file_name="åˆä½µçµæœ.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        key="download_main"
    )
