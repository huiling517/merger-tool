import streamlit as st
import pandas as pd
import io
from functools import reduce


# --- é€šç”¨è¼”åŠ©å‡½æ•¸ ---
def to_excel(df):
    """å°‡ DataFrame è½‰æ›ç‚ºå¯ä¾›ä¸‹è¼‰çš„ Excel Bytes ç‰©ä»¶"""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='åˆä½µçµæœ')
    processed_data = output.getvalue()
    return processed_data


def read_and_clean_sheet(file_obj, sheet_name, header_index=0):
    """è®€å–æŒ‡å®šçš„ Excel å·¥ä½œè¡¨ä¸¦é€²è¡ŒåŸºæœ¬æ¸…ç†"""
    # æ¯æ¬¡è®€å–å‰å°‡æª”æ¡ˆæŒ‡é‡ç§»åˆ°é–‹é ­
    file_obj.seek(0)
    df = pd.read_excel(file_obj, sheet_name=sheet_name, header=header_index)
    df.columns = [str(col).strip() for col in df.columns] # æ¸…ç†æ¬„ä½åç¨±å‰å¾Œç©ºç™½

    # é¡å‹æ¸…ç†ï¼šå¡«å……ç©ºå€¼ä¸¦è§£æ±ºé¡å‹ä¸ä¸€è‡´å•é¡Œ
    for col in df.columns:
        # å˜—è©¦å°‡æ¬„ä½è½‰æ›ç‚ºæ•¸å­—ï¼Œä¸èƒ½è½‰æ›çš„è¨­ç‚º NaN
        # é€™è£¡ä¸ç›´æ¥è½‰æ›æ‰€æœ‰ç‚º 'str' æ˜¯ç‚ºäº†ä¿ç•™æ•¸å­—çš„è¨ˆç®—ç‰¹æ€§
        try:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            df[col] = df[col].fillna(0) # æ•¸å­—é¡å‹ NaN å¡«å…… 0
        except Exception:
            # å¦‚æœç„¡æ³•è½‰æ›ç‚ºæ•¸å­—ï¼Œå‰‡è¦–ç‚ºæ–‡å­—é¡å‹
            df[col] = df[col].astype(str).fillna('') # æ–‡å­—é¡å‹ NaN å¡«å……ç©ºå­—ä¸²
    return df


# --- Streamlit æ‡‰ç”¨ç¨‹å¼ä»‹é¢ ---
st.set_page_config(page_title="Excel å…¨èƒ½åˆä½µå·¥å…·", page_icon="ğŸ§©", layout="wide")

st.title("ğŸ§© Excel å…¨èƒ½åˆä½µå·¥å…·")

# --- æ¨¡å¼é¸æ“‡ ---
app_mode = st.radio(
    "è«‹é¸æ“‡æ‚¨è¦ä½¿ç”¨çš„å·¥å…·æ¨¡å¼ï¼š",
    ('é›™æª”æŸ¥æ‰¾åˆä½µ (VLOOKUP)', 'å¤šæª”åˆä½µ (ç¸±å‘/æ©«å‘)'),
    horizontal=True,
)
st.divider()

# åˆå§‹åŒ– session_state
if 'final_df' not in st.session_state:
    st.session_state.final_df = None
if 'duplication_warning_keys' not in st.session_state:
    st.session_state.duplication_warning_keys = []

# ======================================================================
# æ¨¡å¼ä¸€ï¼šé›™æª”æŸ¥æ‰¾åˆä½µ (VLOOKUP)
# ======================================================================
if app_mode == 'é›™æª”æŸ¥æ‰¾åˆä½µ (VLOOKUP)':
    st.header("æ¨¡å¼ï¼šé›™æª”æŸ¥æ‰¾åˆä½µ (VLOOKUP)")
    st.markdown("æ­¤æ¨¡å¼æœƒä»¥**å·¦è¡¨**ç‚ºåŸºç¤ï¼Œå¾**å³è¡¨**ä¸­æŸ¥æ‰¾ç¬¦åˆæ¢ä»¶çš„è³‡æ–™ï¼Œä¸¦å°‡æŒ‡å®šæ¬„ä½æ–°å¢è‡³å·¦è¡¨ã€‚")

    st.subheader("æ­¥é©Ÿä¸€ï¼šä¸Šå‚³æª”æ¡ˆä¸¦é¸æ“‡å·¥ä½œè¡¨")
    col1, col2 = st.columns(2)
    df_left, df_right = None, None

    with col1:
        st.markdown("##### ğŸ‘ˆ ä¸»è¦æª”æ¡ˆ (å·¦è¡¨)")
        uploaded_file_left = st.file_uploader("é€™æ˜¯æ‚¨è¦ä¿ç•™æ‰€æœ‰è³‡æ–™çš„æª”æ¡ˆ", type=["xlsx", "xls"], key="uploader_left")
        if uploaded_file_left:
            try:
                file_buffer_left = io.BytesIO(uploaded_file_left.getvalue())
                # é‡ç½®æ–‡ä»¶æŒ‡é‡
                file_buffer_left.seek(0)
                sheet_names_left = pd.ExcelFile(file_buffer_left).sheet_names
                left_sheet_name = st.selectbox("é¸æ“‡ä¸»è¦å·¥ä½œè¡¨", sheet_names_left, key="sheet_left")
                header_left = st.number_input("å·¦è¡¨æ¨™é ­åœ¨ç¬¬å¹¾åˆ—?", min_value=1, value=1, key="header_left")
                if left_sheet_name:
                    df_left = read_and_clean_sheet(file_buffer_left, left_sheet_name, header_left - 1)
                    st.write("å·¦è¡¨é è¦½ï¼š")
                    st.dataframe(df_left.head(), height=200)
            except Exception as e:
                st.error(f"è®€å–å·¦è¡¨å¤±æ•—: {e}")

    with col2:
        st.markdown("##### ğŸ‘‰ æŸ¥æ‰¾è³‡æ–™æª”æ¡ˆ (å³è¡¨)")
        uploaded_file_right = st.file_uploader("é€™æ˜¯æ‚¨è¦å¾ä¸­æå–è³‡æ–™çš„æª”æ¡ˆ", type=["xlsx", "xls"], key="uploader_right")
        if uploaded_file_right:
            try:
                file_buffer_right = io.BytesIO(uploaded_file_right.getvalue())
                # é‡ç½®æ–‡ä»¶æŒ‡é‡
                file_buffer_right.seek(0)
                sheet_names_right = pd.ExcelFile(file_buffer_right).sheet_names
                right_sheet_name = st.selectbox("é¸æ“‡æŸ¥æ‰¾è³‡æ–™çš„å·¥ä½œè¡¨", sheet_names_right, key="sheet_right")
                header_right = st.number_input("å³è¡¨æ¨™é ­åœ¨ç¬¬å¹¾åˆ—?", min_value=1, value=1, key="header_right")
                if right_sheet_name:
                    df_right = read_and_clean_sheet(file_buffer_right, right_sheet_name, header_right - 1)
                    st.write("å³è¡¨é è¦½ï¼š")
                    st.dataframe(df_right.head(), height=200)
            except Exception as e:
                st.error(f"è®€å–å³è¡¨å¤±æ•—: {e}")

    if df_left is not None and df_right is not None:
        st.divider()
        st.subheader("æ­¥é©ŸäºŒï¼šè¨­å®šåˆä½µæ¢ä»¶ä¸¦åŸ·è¡Œ")
        # ç§»é™¤å…±åŒæ¬„ä½ä¸­çš„ç©ºç™½å­—å…ƒ
        common_columns = list(set(df_left.columns) & set(df_right.columns))

        if not common_columns:
            st.error("éŒ¯èª¤ï¼šå…©å€‹å·¥ä½œè¡¨ä¹‹é–“æ²’æœ‰ä»»ä½•å…±åŒçš„æ¬„ä½åç¨±ï¼Œç„¡æ³•é€²è¡Œåˆä½µã€‚è«‹æª¢æŸ¥æ¨™é ­åˆ—å’Œæ¬„ä½åç¨±ã€‚")
        else:
            with st.form("vlookup_form"):
                # é¸æ“‡å¤šéµåˆä½µçš„éµå€¼
                merge_keys = st.multiselect("é¸æ“‡ç”¨ä¾†å°æ‡‰çš„æ¬„ä½ (å…±åŒç´¢å¼•éµ)", common_columns, default=common_columns[:1])
                
                # ç¢ºä¿å³è¡¨é¸å–çš„æ¬„ä½ä¸åŒ…å«åˆä½µéµï¼Œä¸¦æ’é™¤æ‰å·²å­˜åœ¨çš„å¯èƒ½é‡è¤‡æ¬„ä½
                available_cols_from_right = [col for col in df_right.columns if col not in merge_keys and col not in df_left.columns]
                
                # è€ƒæ…®åˆ°å·¦è¡¨å·²ç¶“æœ‰çš„æ¬„ä½å¯èƒ½èˆ‡å³è¡¨ééµå€¼æ¬„ä½é‡åï¼Œæ‡‰æç¤ºç”¨æˆ¶
                # é€™è£¡ç¯©é¸å‡ºå³è¡¨ä¸­æœ‰ï¼Œä½†å·¦è¡¨æ²’æœ‰çš„æ¬„ä½ï¼Œä½œç‚ºå¯ä¾›é¸æ“‡çš„æ¬„ä½
                cols_to_add_from_right = [col for col in df_right.columns if col not in df_left.columns and col not in merge_keys]
                
                cols_to_merge = st.multiselect("é¸æ“‡è¦å¾å³è¡¨åŠ å…¥åˆ°å·¦è¡¨çš„æ¬„ä½", cols_to_add_from_right, default=cols_to_add_from_right)

                submitted_vlookup = st.form_submit_button("ğŸš€ åŸ·è¡ŒæŸ¥æ‰¾åˆä½µ", type="primary")

            if submitted_vlookup:
                st.session_state.final_df = None
                st.session_state.duplication_warning_keys = []

                if not merge_keys:
                    st.warning("è«‹é¸æ“‡è‡³å°‘ä¸€å€‹ç”¨ä¾†å°æ‡‰çš„å…±åŒç´¢å¼•éµã€‚")
                else:
                    with st.spinner("æ­£åœ¨åˆä½µè³‡æ–™ä¸¦é€²è¡Œåˆ†æ..."):
                        try:
                            # ç¢ºä¿éµå€¼æ¬„ä½é¡å‹ä¸€è‡´
                            for key in merge_keys:
                                df_left[key] = df_left[key].astype(str).fillna('')  # å¼·åˆ¶è½‰ç‚ºæ–‡å­—å‹
                                df_right[key] = df_right[key].astype(str).fillna('')  # å¼·åˆ¶è½‰ç‚ºæ–‡å­—å‹

                            # è™•ç†å³è¡¨ä¸­çš„é‡è¤‡éµå€¼ï¼šä¿ç•™ç¬¬ä¸€å€‹
                            # å¦å‰‡VLOOKUPæ•ˆæœæœƒåƒExcelä¸€æ¨£ï¼Œåªæœƒæ‰¾åˆ°ç¬¬ä¸€å€‹åŒ¹é…é …
                            df_right_unique = df_right.drop_duplicates(subset=merge_keys, keep='first')
                            
                            # é¸æ“‡å³è¡¨éœ€è¦çš„æ¬„ä½
                            # ç¢ºä¿åªé¸æ“‡è¦åˆä½µçš„æ¬„ä½å’Œéµå€¼æ¬„ä½
                            df_right_selected = df_right_unique[merge_keys + cols_to_merge]

                            # åŸ·è¡Œåˆä½µ
                            # ä½¿ç”¨ `left` åˆä½µä»¥å·¦è¡¨ç‚ºæº–
                            merged_df = pd.merge(df_left, df_right_selected, on=merge_keys, how='left')

                            # æ–°å¢ï¼šç¯©é¸å‡ºå³è¡¨æœªåŒ¹é…åˆ°å·¦è¡¨çš„è³‡æ–™
                            # é€™è£¡è¦ç”¨åŸå§‹çš„df_rightä¾†æ¯”è¼ƒï¼Œè€Œä¸æ˜¯df_right_unique
                            left_keys_set = set(df_left[merge_keys].apply(lambda x: tuple(x), axis=1))
                            unmatched_df = df_right[
                                ~df_right[merge_keys].apply(lambda x: tuple(x), axis=1).isin(left_keys_set)
                            ]
                            if not unmatched_df.empty:
                                st.warning("ä»¥ä¸‹ç‚ºæœªèƒ½åŒ¹é…åˆ°å·¦è¡¨è³‡æ–™çš„å³è¡¨è¨˜éŒ„ï¼ˆå°‡ä¸åŒ…å«åœ¨åˆä½µçµæœä¸­ï¼‰ï¼š")
                                st.dataframe(unmatched_df, use_container_width=True)

                            # å„²å­˜çµæœ
                            st.session_state.final_df = merged_df
                            st.success("ğŸ‰ æŸ¥æ‰¾åˆä½µæˆåŠŸï¼")

                        except Exception as e:
                            st.error(f"åˆä½µå¤±æ•—: {e}")

# ==============================================================================
# æ¨¡å¼äºŒï¼šå¤šæª”åˆä½µ (ç¸±å‘/æ©«å‘)
# ==============================================================================
elif app_mode == 'å¤šæª”åˆä½µ (ç¸±å‘/æ©«å‘)':
    st.header("æ¨¡å¼ï¼šå¤šæª”åˆä½µ (ç¸±å‘/æ©«å‘)")
    st.markdown("æ­¤æ¨¡å¼å¯åˆä½µå¤šå€‹æª”æ¡ˆï¼Œæˆ–å–®ä¸€æª”æ¡ˆå…§çš„å¤šå€‹å·¥ä½œè¡¨ã€‚")

    uploaded_files = st.file_uploader(
        "è«‹ä¸Šå‚³æ‚¨æ‰€æœ‰è¦è™•ç†çš„ Excel æª”æ¡ˆ",
        type=['xlsx', 'xls'],
        accept_multiple_files=True,
        key="multi_file_uploader"
    )

    if uploaded_files:
        with st.form("multi_merge_form"):
            st.subheader("1. åˆä½µæ¨¡å¼è¨­å®š")
            merge_type = st.radio("è«‹é¸æ“‡åˆä½µæ–¹å¼ï¼š", ('ç¸±å‘åˆä½µ (ä¸Šä¸‹å †ç–Š)', 'æ©«å‘åˆä½µ (å·¦å³æ‹¼æ¥)'), horizontal=True)
            header_row_from_user = st.number_input("æ‰€æœ‰æª”æ¡ˆçš„æ¨™é ­ (Header) éƒ½åœ¨ç¬¬å¹¾åˆ—ï¼Ÿ", min_value=1, value=1)

            file_configs = {}
            for uploaded_file in uploaded_files:
                try:
                    file_buffer = io.BytesIO(uploaded_file.getvalue())
                    # é‡ç½®æ–‡ä»¶æŒ‡é‡
                    file_buffer.seek(0)
                    xls = pd.ExcelFile(file_buffer)
                    sheet_names = xls.sheet_names
                    file_configs[uploaded_file.name] = {"file_object": file_buffer, "sheet_names": sheet_names}
                except Exception as e:
                    st.error(f"è®€å–æª”æ¡ˆ '{uploaded_file.name}' çš„å·¥ä½œè¡¨åˆ—è¡¨å¤±æ•—: {e}")

            join_keys = []
            join_how = "inner"

            st.divider()
            st.subheader("2. æª”æ¡ˆèˆ‡å·¥ä½œè¡¨è¨­å®š")
            all_selected_sheets_info = []
            for filename, config in file_configs.items():
                selected_sheets = st.multiselect(
                    f"æª”æ¡ˆ: `{filename}` - è«‹å‹¾é¸è¦åˆä½µçš„å·¥ä½œè¡¨",
                    options=config["sheet_names"],
                    default=config["sheet_names"][0] if config["sheet_names"] else None,
                    key=f"sheets_{filename}"
                )
                config["selected_sheets"] = selected_sheets
                for sheet in selected_sheets:
                    all_selected_sheets_info.append((config["file_object"], sheet, filename)) # å¢åŠ  filename

            if merge_type == 'æ©«å‘åˆä½µ (å·¦å³æ‹¼æ¥)':
                st.divider()
                st.subheader("3. æ©«å‘åˆä½µå°ˆç”¨è¨­å®š")

                common_columns_for_key = []
                if all_selected_sheets_info:
                    try:
                        # è®€å–æ‰€æœ‰é¸å®šå·¥ä½œè¡¨çš„ç¬¬ä¸€å€‹ DataFrame ä»¥è¨ˆç®—å…±åŒæ¬„ä½
                        # åªè®€å–ç¬¬ä¸€å€‹æª”æ¡ˆçš„ç¬¬ä¸€å€‹å·¥ä½œè¡¨ä¾†åˆå§‹åŒ–ï¼Œé¿å…é‡è¤‡è®€å–æ‰€æœ‰
                        # é€™è£¡çš„é‚è¼¯éœ€è¦èª¿æ•´ï¼Œæ‡‰è©²æ˜¯è®€å–æ‰€æœ‰é¸å®šå·¥ä½œè¡¨çš„åˆ—åé›†åˆï¼Œç„¶å¾Œå–äº¤é›†
                        list_of_all_cols = []
                        for f_obj, s_name, _ in all_selected_sheets_info:
                             df_temp = read_and_clean_sheet(f_obj, s_name, header_row_from_user - 1)
                             list_of_all_cols.append(set(df_temp.columns))
                        
                        if list_of_all_cols:
                            common_columns_for_key = list(set.intersection(*list_of_all_cols))
                            # æ’é™¤ Streamlit çš„å…§éƒ¨ key æ¬„ä½ï¼Œå¦‚æœæœ‰çš„è©±
                            common_columns_for_key = [col for col in common_columns_for_key if not str(col).startswith('Unnamed:')]


                    except Exception as e:
                        st.warning(f"è¨ˆç®—å…±åŒæ¬„ä½æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

                if not common_columns_for_key:
                    st.warning("æ‚¨ç›®å‰é¸æ“‡çš„å·¥ä½œè¡¨ä¹‹é–“æ²’æœ‰å…±åŒæ¬„ä½ï¼Œæˆ–åªæœ‰ä¸€å€‹å·¥ä½œè¡¨ï¼Œç„¡æ³•é€²è¡Œæ©«å‘åˆä½µã€‚è«‹ç¢ºèªé¸å–çš„æª”æ¡ˆå’Œå·¥ä½œè¡¨ã€‚")
                else:
                    join_keys = st.multiselect("è«‹é¸æ“‡ç”¨ä¾†å°é½Šçš„ã€Œå…±åŒæ¬„ä½ã€(Keys)", common_columns_for_key,
                                               default=common_columns_for_key[:1])

                merge_options_display = {
                    "å…§é€£æ¥ (Inner Join) - åªä¿ç•™æ‰€æœ‰è¡¨ä¸­å…±æœ‰çš„è³‡æ–™": "inner",
                    "å¤–é€£æ¥ (Outer Join) - ä¿ç•™æ‰€æœ‰è¡¨ä¸­å‡ºç¾éçš„è³‡æ–™": "outer",
                    "å·¦é€£æ¥ (Left Join) - ä»¥ç¬¬ä¸€å€‹é¸æ“‡çš„è¡¨ç‚ºåŸºç¤": "left",
                }
                selected_display = st.selectbox(
                    "é¸æ“‡åˆä½µé¡å‹",
                    options=list(merge_options_display.keys()),
                    help="æ±ºå®šå¦‚ä½•è™•ç†åœ¨ä¸åŒè¡¨ä¸­ç„¡æ³•å°æ‡‰çš„è³‡æ–™ã€‚"
                )
                join_how = merge_options_display[selected_display]

            st.divider()
            st.subheader("4. å…¶ä»–è¨­å®š")
            add_source_col = st.checkbox("æ–°å¢ã€Œä¾†æºæª”æ¡ˆ/å·¥ä½œè¡¨ã€æ¬„ä½ (åƒ…åœ¨ç¸±å‘åˆä½µæ™‚æœ‰æ•ˆ)", value=True)
            submitted = st.form_submit_button("ğŸš€ åŸ·è¡Œå¤šæª”åˆä½µ", type="primary")

        if submitted:
            st.session_state.final_df = None

            all_dfs_to_merge = []
            with st.spinner('æ­£åœ¨è®€å–æ‰€æœ‰é¸å®šçš„å·¥ä½œè¡¨...'):
                for f_obj, sheet_name, filename in all_selected_sheets_info:
                    df = read_and_clean_sheet(f_obj, sheet_name, header_row_from_user - 1)
                    if add_source_col and merge_type == 'ç¸±å‘åˆä½µ (ä¸Šä¸‹å †ç–Š)':
                        df['ä¾†æºæª”æ¡ˆ'] = filename
                        df['ä¾†æºå·¥ä½œè¡¨'] = sheet_name
                    all_dfs_to_merge.append(df)

            if not all_dfs_to_merge:
                st.warning("æœªæˆåŠŸè®€å–ä»»ä½•å·¥ä½œè¡¨ã€‚")
            else:
                merged_df = None
                with st.spinner('æ­£åœ¨åŸ·è¡Œåˆä½µ...'):
                    try:
                        if merge_type == 'ç¸±å‘åˆä½µ (ä¸Šä¸‹å †ç–Š)':
                            # ç¢ºä¿æ‰€æœ‰ DataFrame åœ¨åˆä½µå‰æœ‰ç›¸åŒçš„åˆ—ï¼Œç¼ºå¤±çš„åˆ—ç”¨ NaN å¡«å……
                            # é€™æ¨£å³ä½¿æŸäº›æª”æ¡ˆå°‘äº†æŸåˆ—ï¼Œåˆä½µå¾Œçµæœä¹ŸæœƒåŒ…å«è©²åˆ—
                            merged_df = pd.concat(all_dfs_to_merge, ignore_index=True, sort=False)
                        else:  # æ©«å‘åˆä½µ
                            if not join_keys:
                                st.error("æ©«å‘åˆä½µéŒ¯èª¤ï¼šå¿…é ˆæä¾›ã€Œå…±åŒæ¬„ä½ã€ã€‚")
                            elif len(all_dfs_to_merge) < 2:
                                st.warning("æ©«å‘åˆä½µè‡³å°‘éœ€è¦å…©å€‹å·¥ä½œè¡¨æ‰èƒ½é€²è¡Œæ‹¼æ¥ã€‚")
                            else:
                                processed_dfs = []
                                for i, df in enumerate(all_dfs_to_merge):
                                    # è¤‡è£½ df ä»¥é¿å…ä¿®æ”¹åŸå§‹ DataFrame
                                    df_copy = df.copy() 
                                    # ç‚ºé join_keys æ¬„ä½æ·»åŠ å¾Œç¶´ä»¥é¿å…è¡çª
                                    # åƒ…å°ééµå€¼çš„ä¸”ä¸åœ¨å…¶ä»– df ä¸­çš„æ¬„ä½é€²è¡Œé‡å‘½åï¼Œä»¥ä¿ç•™æ‰€æœ‰æ•¸æ“š
                                    renamed_columns = {}
                                    for col in df_copy.columns:
                                        if col not in join_keys:
                                            # ç”¢ç”Ÿå”¯ä¸€çš„å¾Œç¶´ï¼Œä¾‹å¦‚ _Sheet1_File1, _Sheet2_File1
                                            # é€™è£¡æˆ‘å€‘ä½¿ç”¨ä¸€å€‹ç°¡å–®çš„è¨ˆæ•¸å™¨ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ filename_sheetname
                                            renamed_columns[col] = f"{col}__{i+1}" 
                                    df_copy = df_copy.rename(columns=renamed_columns)
                                    processed_dfs.append(df_copy)

                                # ä½¿ç”¨ reduce é€²è¡Œè¿­ä»£åˆä½µ
                                # ç¢ºä¿ join_keys çš„æ•¸æ“šé¡å‹åœ¨æ‰€æœ‰ DataFrame ä¸­éƒ½ä¸€è‡´
                                for i, df in enumerate(processed_dfs):
                                    for key in join_keys:
                                        if key in df.columns:
                                            df[key] = df[key].astype(str) # å¼·åˆ¶è½‰æ›ç‚ºå­—ä¸²é¡å‹

                                merged_df = reduce(
                                    lambda left, right: pd.merge(left, right, on=join_keys, how=join_how, suffixes=(f'_{len(left.columns)}', f'_{len(right.columns)}')) , processed_dfs
                                )

                                # æ¸…ç†å¯èƒ½ç”± suffixes ç”¢ç”Ÿè€Œåˆæœªä½¿ç”¨çš„é‡è¤‡æ¬„ä½åç¨±
                                # ä¾‹å¦‚ 'æ¬„ä½åç¨±__1_df_x', 'æ¬„ä½åç¨±__1_df_y'
                                # é€™éœ€è¦æ›´ç´°ç·»çš„è™•ç†ï¼Œç›®å‰ç°¡åŒ–è™•ç†
                                # ç•¶ suffixes å­˜åœ¨æ™‚ï¼Œpandas æœƒè‡ªå‹•è™•ç†é‡åï¼Œé€™è£¡ä¸»è¦æ˜¯ç¢ºä¿æ•¸æ“šå®Œæ•´
                                
                                # åœ¨ `reduce` å‡½æ•¸ä¸­çš„ `suffixes` åƒæ•¸æœƒè‡ªå‹•è™•ç†é™¤äº† `on` éµä¹‹å¤–çš„é‡è¤‡æ¬„ä½ã€‚
                                # å¦‚æœä¸€å€‹æ¬„ä½åç¨±åœ¨ `left` å’Œ `right` DataFrame ä¸­éƒ½å­˜åœ¨ï¼Œä½†ä¸æ˜¯ `on` éµï¼Œ
                                # é‚£éº¼å®ƒæœƒè¢«åŠ ä¸Š `_x` å’Œ `_y` å¾Œç¶´ã€‚
                                # ä¾‹å¦‚ï¼šå¦‚æœ `df1` æœ‰ `ID, Name, Value`ï¼Œ`df2` æœ‰ `ID, Name, Date`
                                # join_keys=['ID']
                                # åˆä½µå¾Œæœƒæ˜¯ `ID, Name_x, Value, Name_y, Date`
                                # å¦‚æœæˆ‘å€‘åœ¨ä¹‹å‰å·²ç¶“ç‚ºééµå€¼æ¬„ä½åšäº†å”¯ä¸€çš„é‡å‘½å (ä¾‹å¦‚ `Name__1`, `Name__2`)ï¼Œ
                                # é‚£éº¼ `suffixes` å°±ä¸æœƒç”¢ç”Ÿ `_x`, `_y` äº†ï¼Œå› ç‚ºæ¬„ä½å·²ç¶“æ˜¯å”¯ä¸€çš„ã€‚
                                # æ‰€ä»¥ï¼Œæˆ‘çš„é‡å‘½åç­–ç•¥æ‡‰å…ˆæ–¼ `pd.merge` çš„ `suffixes` ç™¼ç”Ÿï¼Œä»¥ç¢ºä¿å”¯ä¸€æ€§ã€‚
                                # ä¸Šé¢çš„ `renamed_columns` å·²ç¶“å¯¦ä½œäº†é€™é»ã€‚

                        if merged_df is not None:
                            st.session_state.final_df = merged_df
                            st.success("ğŸ‰ åˆä½µæˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"åˆä½µå¤±æ•—: {e}")


# --- é€šç”¨çµæœé¡¯ç¤ºå€ ---
if 'final_df' in st.session_state and st.session_state.final_df is not None:
    st.divider()
    st.header("âœ… åˆä½µçµæœé è¦½èˆ‡ä¸‹è¼‰")
    final_df = st.session_state.final_df
    st.info(f"åˆä½µçµæœï¼šå…± {final_df.shape[0]} ç­†è³‡æ–™ï¼Œ{final_df.shape[1]} å€‹æ¬„ä½ã€‚")
    st.dataframe(final_df, use_container_width=True)

    excel_data = to_excel(final_df)
    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰åˆä½µçµæœ",
        data=excel_data,
        file_name="åˆä½µçµæœ.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        key="download_main"
    )

